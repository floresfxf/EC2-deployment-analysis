{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Project: Clever Name Here\n",
    "### Francisco Xavier Flores and Pam Needle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The modernization of web services has recently been increasingly pushing for deployment in infrastructure-as-a-service (IaaS) clouds such as Amazon EC2, Windows Azure, and Rackspace. Industry claims that over 1% of Internet traffic goes to EC2 and that outages in EC2 are reputed to hamper a huge variety of services. Our goal is to determine who is using Iaas Clouds (more specifically EC2 clouds), how these services are using the cloud, and finally use (Planet-Lab or EDNS Queries) to estimate the impact of wide-area route outages. \n",
    "\n",
    "**Warning** Acquiring and cleaning data is a messy process, but your approach shouldn't be.  Approach this lab with a rigorous problem solving mindset.  Design and implement a solution that is robust to unexpected inputs and handles these anomalies gracefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you make changes to your code and rerun a python notebook, your changes may not be detected because python is lazy about reloading modules.  The following two lines will force reloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Set the context (introduce the dataset and questions), provide motivation for why these are interesting questions to explore. The introduction should end with a brief summary of your findings.**\n",
    "\n",
    "- Background: \n",
    "- What is EC2?\n",
    "- What is the cloud?\n",
    "- all those networky terms explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II. Methodology (2 pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Describe, at a high-level, the methods you employed. Focus more attention on the more challenging/interesting/novel aspects. Provide references to your code as appropriate.**\n",
    "- describes your data and the methodologies used to acquire, clean and prepare your data\n",
    "- analysis with references to code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquistion\n",
    "\n",
    "Amazon previously published \"Alexa Top 1m Sites\" which was a list of the the top 1 million web site domains ordered by Alexa Traffic Rank. This data used to be publically available, however, Amazon now charges a fee. We will be working with the top 1m domains published in 2013 as a result. We extraced a list of subdomains from a dataset derived from the Alexa's 2013 Top 1m domains that contains all subdomains for each domain in the top 1m [http://pages.cs.wisc.edu/~keqhe/imc2013/Alexa_subdomain_dns_records.tar.gz]. Note: these are all subdomains from 2013 so we are going off the assumption that these have remained the same. \n",
    "We created this list using the following command: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "awk -F'#' '!seen[$2]++ {print $1, $2}' ALL_subdomains_Alexa_top1m.csv > uniquewithrank.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- why subdomains not domains? you can host subdomain on different hosts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III. Results (2 pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Present your findings through:**\n",
    "- statistics\n",
    "- tables\n",
    "- visualizations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Conclusions (1/2 page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Summarize the conclusions of your study. This might include a discussion of future work. **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV. Related Work (1/2 page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO: Briefly describe related work on this topic (if applicable) **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping and cleaning the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the file `scrape.py`, write a function called `scrape_cherry_blossoms()` that scrapes the web pages of race results for a given set of years and genders and writes the results to one file and errors to another.  The results file should be a CSV file that looks something like this:\n",
    "\n",
    "    year,gender,place,name,hometown,age,time\n",
    "    2010,m,1,Stephen Tum,Kenya,24,45.71666666666667\n",
    "    2010,m,2,Lelisa Desisa,Ethiopia,20,45.733333333333334\n",
    "    ...\n",
    "\n",
    "Notice that race time has been converted to minutes. For more details, see the docstring of `scrape_cherry_blossoms()`.\n",
    "\n",
    "Here are a few guidelines in writing this function:\n",
    "- Before you start, examine the Cherry Blossom results web pages (View Source in your web browser).  You'll notice that the format varies slightly from page to page.  Try to write the code in a general way so that the same approach can be applied to all 28 pages (14 years x 2 genders).\n",
    "- Smart small: debug your program on one year, then two years, etc. before unleashing it on all years.\n",
    "- The web pages contain some unicode characters that may cause problems when you try to write it out to a file.  If string `s` is a unicode string, you can encode it in ASCII as follows: `s.encode('ascii', 'replace')`.\n",
    "- Not only are the pages formatted differently, the *data* varies from page to page.  To aggregate the data across all years, we would like to decide on a uniform data format.  Thus, you will need to make some decisions on how to map each individual result file to this common format.\n",
    "- As is often the case, there is missing data.  Some runners don't have an age, some don't have a time, etc.  Handle missing data as follows: any record that is missing a value for *any* of the *required fields* should be discarded and put into the errors file.  The required fields are those that appear in the CSV example above.\n",
    "- Try to process as many years as you can.  Years 2001, 2006 and 2009 are especially tricky and are considered optional **challenge problems**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invoke your function here, passing in as many years as you can process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named geo",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-25f1949385e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgeo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named geo"
     ]
    }
   ],
   "source": [
    "import geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the space below, explain how you handled time:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compared the format of the results for the different years and determined for each year which column number is to be used for time. Most result years used the 7th or 8th column for gun time/time, except for 2008 which used the 11th column and 1999 which used the 6th column. We created lists for each of those groups and then selected the corresponding regex group for those years. In the cases where some of the columns were empty, we used conditional statements to select the correct regex group. After extracting the correct time value, we used a helper function \"time_in_mins\" to calculate the total time in minutes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `manipulate.py`, write a function called `load_race_data(filename)` that reads a CSV file named `filename` and parses each field into the appropriate type.  The result should be a list of dicts where each dict represents one row of data (i.e., the format shown on p. 129 of DSFS).  For example, if the result file contains men's results from 2010, the ouptut of the `load_race_data` function should look like this:\n",
    "\n",
    "    [\n",
    "     {'name': 'Stephen Tum', 'gender': 'm', 'age': 24, \n",
    "      'year': 2010, 'hometown': 'Kenya', 'place': 1, 'time': 45.71666666666667}, \n",
    "     {'name': 'Lelisa Desisa', 'gender': 'm', 'age': 20, \n",
    "      'year': 2010, 'hometown': 'Ethiopia', 'place': 2, 'time': 45.733333333333334},\n",
    "     ...\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can manipulate the data to answer some basic questions.  \n",
    "\n",
    "1. What is the age range for male runners?\n",
    "2. What is the age range for female runners?\n",
    "3. Who had the fastest running time across all years/genders, how fast did they run and in what year?\n",
    "4. Who had the slowest running time across all years/genders and how fast did they run and in what year?\n",
    "\n",
    "If any of these answers seem odd, go back your data cleaning process and the source data.  If the oddity is due to the source data, you can leave it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
